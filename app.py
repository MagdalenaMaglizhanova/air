import streamlit as st
import pandas as pd
from bs4 import BeautifulSoup
import asyncio
from playwright.async_api import async_playwright

st.set_page_config(page_title="–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –≤—ä–∑–¥—É—Ö–∞ ‚Äì –ü–ª–æ–≤–¥–∏–≤", layout="wide")

st.title("–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –≤—ä–∑–¥—É—Ö–∞ –≤ –ü–ª–æ–≤–¥–∏–≤ (–¥–∞–Ω–Ω–∏ –æ—Ç –ò–ê–û–°)")
st.markdown("–ò–∑—Ç–µ–≥–ª—è–Ω–µ –≤ —Ä–µ–∞–ª–Ω–æ –≤—Ä–µ–º–µ –Ω–∞ –¥–∞–Ω–Ω–∏ –æ—Ç [eea.government.bg/kav](https://eea.government.bg/kav/)")

@st.cache_data(show_spinner=True)
def get_data_sync():
    return asyncio.run(scrape_data())

async def scrape_data():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto("https://eea.government.bg/kav/", timeout=60000)
        await page.wait_for_timeout(10000)

        content = await page.content()
        await browser.close()

        soup = BeautifulSoup(content, "lxml")
        tables = pd.read_html(str(soup))
        for df in tables:
            if df.astype(str).apply(lambda row: row.str.contains("–ü–ª–æ–≤–¥–∏–≤").any(), axis=1).any():
                return df
        return tables[0] if tables else None

if st.button("–ò–∑—Ç–µ–≥–ª–∏ –¥–∞–Ω–Ω–∏—Ç–µ"):
    with st.spinner("–ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏..."):
        df = get_data_sync()
        if df is not None:
            st.success("–î–∞–Ω–Ω–∏—Ç–µ —Å–∞ –∑–∞—Ä–µ–¥–µ–Ω–∏ —É—Å–ø–µ—à–Ω–æ.")
            st.dataframe(df, use_container_width=True)

            csv = df.to_csv(index=False).encode("utf-8")
            st.download_button("üì• –°–≤–∞–ª–∏ –∫–∞—Ç–æ CSV", data=csv, file_name="plovdiv_air.csv", mime="text/csv")
        else:
            st.error("–ù–µ —É—Å–ø—è—Ö–º–µ –¥–∞ –∑–∞—Ä–µ–¥–∏–º —Ç–∞–±–ª–∏—Ü–∞—Ç–∞.")
